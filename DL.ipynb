{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca21384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "\n",
    "def hebbian_learning_rule(input_pattern, weight_matrix):\n",
    "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
    "\n",
    "def perceptron_learning_rule(input_pattern, target, weight_vector, learning_rate):\n",
    "    prediction = np.dot(weight_vector, input_pattern)\n",
    "    error = target - prediction\n",
    "    return weight_vector + learning_rate * error * input_pattern\n",
    "\n",
    "def delta_learning_rule(input_pattern, target, weight_matrix, learning_rate):\n",
    "    prediction = np.dot(weight_matrix, input_pattern)\n",
    "    error = target - prediction\n",
    "    return weight_matrix + learning_rate * np.outer(error, input_pattern)\n",
    "\n",
    "def correlation_learning_rule(input_pattern, weight_matrix):\n",
    "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
    "\n",
    "def out_star_learning_rule(input_pattern, weight_matrix, learning_rate):\n",
    "    return weight_matrix + learning_rate * np.outer(input_pattern, input_pattern)\n",
    "\n",
    "input_size=3\n",
    "hebbian_weights = np.random.rand(input_size, input_size)\n",
    "perceptron_weights=np.random.rand(input_size)\n",
    "delta_weights=np.random.rand(input_size,input_size)\n",
    "correlation_weights=np.random.rand(input_size,input_size)\n",
    "out_star_weights=np.random.rand(input_size,input_size)\n",
    "\n",
    "print(\"Hebbian Weights:\",hebbian_weights)\n",
    "print(\"\\nPerceptron Weights:\",perceptron_weights)\n",
    "print(\"\\nDelta Weights:\",delta_weights)\n",
    "print(\"\\nCorrelation Weights:\",correlation_weights)\n",
    "print(\"\\nOut Star Weights:\",out_star_weights)\n",
    "\n",
    "input_pattern = np.array([0.2,0.5,0.8])\n",
    "target=1\n",
    "\n",
    "hebbian_weights_updated = hebbian_learning_rule(input_pattern, hebbian_weights)\n",
    "\n",
    "perceptron_weights_updated = perceptron_learning_rule(input_pattern, target, perceptron_weights, learning_rate=0.1)\n",
    "\n",
    "delta_weights_updated = delta_learning_rule(input_pattern, target, delta_weights, learning_rate=0.1)\n",
    "\n",
    "correlation_weights_updated = correlation_learning_rule(input_pattern, correlation_weights)\n",
    "\n",
    "out_star_weights_updated = out_star_learning_rule(input_pattern, out_star_weights, learning_rate=0.1)\n",
    "\n",
    "print(\"Hebbian Updated Weights:\", hebbian_weights_updated)\n",
    "print(\"\\nPerceptron Updated Weights:\", perceptron_weights_updated)\n",
    "print(\"\\nDelta Updated Weights:\", delta_weights_updated)\n",
    "print(\"\\nCorrelation Update Weights:\", correlation_weights_updated)\n",
    "print(\"\\nOut Star Updated Weights:\", out_star_weights_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8115c7b-511f-4238-a63e-0923ccde86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_sigmoid():\n",
    "    x = np.linspace(-10,10,100)\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"Sigmoid Output\")\n",
    "    plt.title(\"Sigmoid Activation Function\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_tanh():\n",
    "    x = np.linspace(-10,10,100)\n",
    "    tanh = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    plt.plot(x,tanh)\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"Hyperbolic Tangent Output\")\n",
    "    plt.title(\"Hyperbolic Tangent Function\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_ReLU():\n",
    "    x = np.linspace(-10,10,100)\n",
    "    ReLU = np.maximum(0,x)\n",
    "    plt.plot(x,ReLU)\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"ReLU Output\")\n",
    "    plt.title(\"Rectified Linear Unit\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_LeakyReLU(alpha=0.01):\n",
    "    x = np.linspace(-10,10,100)\n",
    "    LeakyReLU = np.where(x > 0, x, alpha * x)\n",
    "    plt.plot(x,LeakyReLU)\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"LeakyReLU Output\")\n",
    "    plt.title(\"Leaky ReLU\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_ELU(alpha=0.01):\n",
    "    x = np.linspace(-10,10,100)\n",
    "    ELU = np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
    "    plt.plot(x,ELU)\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"ELU Output\")\n",
    "    plt.title(\"Exponential Linear Unit\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_swish(beta=1):\n",
    "    x = np.linspace(-10,10,100)\n",
    "    swish = x * 1 / (1 + np.exp(-(beta * x)))\n",
    "    plt.plot(x,swish)\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"Swish Output\")\n",
    "    plt.title(\"Swish\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_sigmoid()\n",
    "plot_tanh()\n",
    "plot_ReLU()\n",
    "plot_LeakyReLU()\n",
    "plot_ELU()\n",
    "plot_swish()\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x)) # Stability trick\n",
    "    return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "x = np.linspace(-10,10,100)\n",
    "softmax_values = softmax(np.array([x, x/2, x/3]))\n",
    "#plt.subplot(3, 3, 7)\n",
    "for i in range(softmax_values.shape[0]):\n",
    "    plt.plot(x,softmax_values[i], label = f\"Softmax Output {i+1}\")\n",
    "\n",
    "plt.title(\"Softmax Activation Function\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cb8f1-c72d-406b-8536-8815bddec0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x>=0 else 0\n",
    "\n",
    "def perceptron_decision(inputs,weights, bias):\n",
    "    weighted_sum=np.dot(inputs,weights)+bias\n",
    "    return step_function(weighted_sum)\n",
    "\n",
    "dataset = [\n",
    "    {\"inputs\": [1,0,1], \"expected\": 1},\n",
    "    {\"inputs\": [1,1,0], \"expected\": 0},\n",
    "    {\"inputs\": [0,0,1], \"expected\":1},\n",
    "    {\"inputs\": [1,1,1], \"expected\":1},\n",
    "    {\"inputs\": [0,1,0], \"expected\":0}\n",
    "]\n",
    "\n",
    "weights = np.array([0.2, 0.4, 0.2])\n",
    "bias = -0.5\n",
    "correct_predictions=0\n",
    "total_samples=len(dataset)\n",
    "print(\"Inputs\\t\\tPrediction\\tExpected\\tResult\")\n",
    "for data in dataset:\n",
    "    inputs=np.array(data[\"inputs\"])\n",
    "    expected_output = data[\"expected\"]\n",
    "\n",
    "    predicted_output = perceptron_decision(inputs,weights,bias)\n",
    "\n",
    "    if predicted_output == expected_output:\n",
    "        correct_predictions +=1\n",
    "\n",
    "    result = \"Correct\" if predicted_output == expected_output else \"Incorrect\"\n",
    "    print(f\"{inputs}\\t\\t{predicted_output}\\t\\t{expected_output}\\t\\t{result}\")\n",
    "\n",
    "accuracy = (correct_predictions / total_samples) * 100\n",
    "print(f\"\\nModel Accuracy: {accuracy: 2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b425f-719f-4819-9be7-698d46ff339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img1=cv2.imread('/content/bright.jpeg')\n",
    "plt.axis('off')\n",
    "plt.title('Bright image')\n",
    "plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "img2=cv2.imread('/content/dark.jpeg')\n",
    "plt.axis('off')\n",
    "plt.title('Dark image')\n",
    "plt.imshow(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "img3=cv2.imread('/content/medium.jpeg')\n",
    "plt.axis('off')\n",
    "plt.title('Medium image')\n",
    "plt.imshow(cv2.cvtColor(img3,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "histogram=cv2.calcHist([img1],[0],None,[256],[0,256])\n",
    "plt.plot(histogram,color='black')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "colors=['b','g','r']\n",
    "for color in colors:\n",
    "  hist=cv2.calcHist([img1],[i],None,[256],[0,256])\n",
    "  plt.plot(hist,color=color)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "gray_image=cv2.cvtColor(img1,cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_image)\n",
    "plt.title('gray image')\n",
    "plt.show()\n",
    "\n",
    "resized=cv2.resize(src=img1,dsize=(970,220),interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(resized)\n",
    "plt.show()\n",
    "\n",
    "gaussian=cv2.GaussianBlur(resized,(15,5),0)\n",
    "plt.imshow(gaussian)\n",
    "plt.show()\n",
    "\n",
    "canny=cv2.Canny(resized,100,200)\n",
    "plt.imshow(canny)\n",
    "plt.title('Canny')\n",
    "plt.show()\n",
    "\n",
    "brighted=cv2.addWeighted(resized,1.2,resized,0,70)\n",
    "plt.imshow(brighted)\n",
    "plt.show()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array,array_to_img\n",
    "\n",
    "datagen=ImageDataGenerator(rotation_range=20,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest')\n",
    "img=load_img('/content/dark.jpeg')\n",
    "x=img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "\n",
    "num_images=5\n",
    "augmented_images=[]\n",
    "for i,batch in enumerate(datagen.flow(x,batch_size=1)):\n",
    "  augmented_images.append(array_to_img(batch[0]))\n",
    "  if i>=num_images-1:\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,num_images+1,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "\n",
    "for i in range(len(augmented_images)):\n",
    "  plt.subplot(1,num_images+1,i+1+1)\n",
    "  plt.imshow(augmented_images[i])\n",
    "  plt.title('Augmented')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from skimage import io,exposure\n",
    "img=io.imread('/content/dark.jpeg',as_gray=True)\n",
    "equalized=exposure.equalize_hist(img)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title('Input image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(equalized,cmap='gray')\n",
    "plt.title('Equalized image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "binary_img=cv2.imread('/content/bright.jpeg',cv2.IMREAD_GRAYSCALE)\n",
    "_,binary_img=cv2.threshold(binary_img,127,255,cv2.THRESH_BINARY)\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "eroded_image=cv2.erode(binary_img,kernel,iterations=1)\n",
    "dilated_image=cv2.dilate(binary_img,kernel,iterations=1)\n",
    "opening=cv2.morphologyEx(binary_img,cv2.MORPH_OPEN,kernel)\n",
    "closing=cv2.morphologyEx(binary_img,cv2.MORPH_CLOSE,kernel)\n",
    "gradient=cv2.morphologyEx(binary_img,cv2.MORPH_GRADIENT,kernel)\n",
    "\n",
    "titles=['Original','Erosion','Dilation','Opening','Closing','Gradient']\n",
    "images=[binary_img,eroded_image,dilated_image,opening,closing,gradient]\n",
    "for i in range(len(images)):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(images[i],cmap='gray')\n",
    "  plt.title(titles[i])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe0f98-1adf-4f21-a009-552f7f0c02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "!curl -o style.jpg https://i.imgur.com/9ooB60I.jpg\n",
    "!curl -o content.jpg https://i.imgur.com/F28w3Ac.jpg\n",
    "\n",
    "def load_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not read image at path: {path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "content_image = load_img('content.jpg')   \n",
    "style_image = load_img('style.jpg')       \n",
    "\n",
    "model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "\n",
    "def apply_style(content_image, style_image):\n",
    "    content_image = content_image.reshape(1, *content_image.shape).astype('float32')\n",
    "    style_image = cv2.resize(style_image, (256, 256))\n",
    "    style_image = style_image.reshape(1, *style_image.shape).astype('float32')\n",
    "    outputs = model(tf.constant(content_image), tf.constant(style_image))\n",
    "    stylized_image = outputs[0]\n",
    "    return stylized_image\n",
    "\n",
    "stylized_img = apply_style(content_image, style_image)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(stylized_img[0])\n",
    "plt.title(\"Stylized Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462c982-f1a9-4f79-b0e4-69f26ae20b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "cifar_10_classes = [\n",
    "    \"Airplane\",\n",
    "    \"Automobile\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Ship\",\n",
    "    \"Truck\"\n",
    "]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "plt.title(cifar_10_classes[y_train[0][0]])\n",
    "plt.axis(\"off\")\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "y_train = one_hot_encoder.fit_transform(y_train).toarray()\n",
    "y_test = one_hot_encoder.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8d6d6-237a-4a5a-bc95-30a575e73569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "dataset = keras.datasets.mnist\n",
    "\n",
    "class_names = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "(x_train, y_train), (x_test, y_test) = dataset.load_data()\n",
    "x_train=x_train.reshape((x_train.shape[0], x_train.shape[1],x_train.shape[2],1))\n",
    "x_test=x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "print(x_train.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(class_names[y_train[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "model =keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=1),\n",
    "    keras.layers.Conv2D (64, (3,3), input_shape=(28,28,1), activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=1),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense (64, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,y_train, epochs=5, callbacks=keras.callbacks.EarlyStopping(patience=2))\n",
    "\n",
    "model.evaluate(x_test,y_test)\n",
    "\n",
    "sample_img = x_test[0]\n",
    "sample_img.shape\n",
    "plt.imshow(sample_img)\n",
    "\n",
    "img = np.expand_dims(sample_img,axis=0)\n",
    "img.shape\n",
    "\n",
    "pred = model.predict(img)\n",
    "\n",
    "pred\n",
    "\n",
    "print(f\"Predicted; {class_names[np.argmax(pred)]}\\nActual: {class_names[y_test[0]]}\")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
